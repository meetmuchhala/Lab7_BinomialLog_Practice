---
__---
title: "Lab7_prac"
author: "MeetMuchhala"
format: html
editor: visual
---us
---

Lab 7: Post-Lab Practice
In the same repository as Lab 7, create a new Quarto document and set it up with appropriate options.
Delete the template text, and create a new code chunk. Attach any packages you expect to use. 

Overview
For this exercise, you will use the penguins data from the palmerpenguins package.  There are several categorical variables we could use to create a predictive binomial logistic regression model.  More details below on the coding portion of the task.  But first, some conceptual questions!

Option 1: 


With this selected model, if you used cross-fold validation, retrain this model using the entire dataset.  Describe each of the variables and coefficients, including examples similar to those in the conceptual questions - e.g., for a given increase in variable X, how much more likely is the penguin to be species Y..

## Setting up libraries

```{r}
library(tidyverse)
library(here)
library(tidymodels)
library(rsample)

```

## Dataset

```{r}
library(palmerpenguins)

penguins_df <- penguins %>% 
  janitor::clean_names()

write_csv(penguins_df, here('data/penguins.csv'))

penguins_df <-  read_csv(here('data/penguins.csv'))

```

## Filter the penguins dataset to just include Adelies and Chinstraps (fairly similar in size, compared to Gentoos). 

```{r}

adelchin_df <- penguins_df %>% 
  filter(species == c('Adelie', 'Chinstrap')) 
 

adelchin_df <- adelchin_df %>%
  mutate(sex = factor(sex),
         species = factor(species)) 

head(adelchin_df)
  


```

##  Do some exploratory plots to identify a few good variables that might help in this classification.  Do these variables make sense, why or why not?

```{r}

ggplot(adelchin_df, aes(x = sex, fill = species)) + geom_bar() # sex is varying in the count levels, not sure if 

ggplot(adelchin_df, aes(x = bill_length_mm, fill = species)) + geom_boxplot() ## relevant variance. Bill length is definitely an identifying parameter. with/without sex model

ggplot(adelchin_df, aes(x = bill_depth_mm, fill = species)) + geom_boxplot() ## . Adelie and Chinstrap male and females have similar bill depth length, might not be as significant. try this in model without sex

ggplot(adelchin_df, aes(x = flipper_length_mm, fill =species )) + geom_boxplot() ## few outliers but big variance. Flipper length has the most variance. Female of both species have some overlap, but male are clearly diffenret. with and without sex

ggplot(adelchin_df, aes(x = body_mass_g, fill = species)) + geom_boxplot() ## mass of male species overlap and female dont. but without sex, it is actually adelie is lighter, so this one in without sex

## Overall it appears that bill length and sex might be a strong model to use. and we can try another model with all parameters.

levels(adelchin_df$species)
```

## Create two candidate model formulas using these predictor variables.  Analyze the filtered dataset and compare the performance of the two candidate models; select one model and explain your selection criteria (e.g., AIC/BIC, K-fold cross validation, AUC).

```{r}
f1 <- species ~ sex + flipper_length_mm 
f2 <- species ~ flipper_length_mm + body_mass_g + sex


blr1 <- glm(formula = f1, data = adelchin_df, family = binomial)


blr2 <- glm(formula = f2, data = adelchin_df, family = binomial)
summary(blr1)
summary(blr2)

#table(adelchin_df %>% select(species,sex, flipper_length_mm))
```

## Using tidymodels

```{r}
adelchin_df %>%
  group_by(species) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(prop = n / sum(n))

## we created the proportion of species between two. It is pretty unequal as we see adelie is 69 percent and the Chinstrap is almost 31 percent.

## now doing a stratified split

set.seed(65)

species_split <- initial_split(adelchin_df, prop = 0.80, strata = species) ## setting aside 80 percent in a stratified split ## make strata = NULL when there is equal or decent proportions of variables

species_train_df <- training(species_split)
species_test_df <- testing(species_split)
```


```{r set up a binary logistic regression model with our data}
blr_mdl <- logistic_reg() %>%
  set_engine('glm') ### this is the default - we could try engines from other packages or functions

blr1_fit <- blr_mdl %>%
  fit(formula = f1, data = species_train_df)

### let's also create a model we know will be bad:
blr2_fit <- blr_mdl %>%
  fit(formula = f2, data = species_train_df)

blr1_fit
blr2_fit

```

```{r}
species_test_predict <- species_test_df %>%
  ### straight up prediction, based on 50% prob threshold (to .pred_class):
  mutate(predict(blr1_fit, new_data = species_test_df)) %>%
  ### but can also get the raw probabilities of class A vs B (.pred_A, .pred_B):
  mutate(predict(blr1_fit, new_data = ., type = 'prob'))
    ### note use of `.` as shortcut for "the current dataframe"


table(species_test_predict %>%
        select(species, .pred_class))

##          .pred_class
#species     Adelie Chinstrap
 # Adelie        14         2
 # Chinstrap      1         6

## checking the accuracy

accuracy(species_test_predict, truth = species, estimate = .pred_class) ## 86.9 percent accuracy for model 1

roc_df <- roc_curve(species_test_predict, truth = species, .pred_Adelie)
autoplot(roc_df)
```
```{r}
### how about model 2
model2_test_df <- species_test_df %>%
  mutate(predict(blr2_fit, new_data = ., type = 'prob')) 

model2_roc_df <- model2_test_df %>%
  roc_curve(truth = species, .pred_Adelie) 

autoplot(model2_roc_df)

### Calculate area under curve - 50% is random guessing, 100% is perfect classifier
yardstick::roc_auc(species_test_predict, truth = species, .pred_Adelie)## 98 percent 
yardstick::roc_auc(model2_test_df, truth = species, .pred_Adelie) ## 86.6 %

```



```{r}
set.seed(6578)
species_train_folds <- vfold_cv(species_train_df, v = 10)
species_train_folds
```

Automates that first step we did!

Now let's create a `workflow` that combines our model and a formula.  We already specified a binary logistic regression model above.  The workflow specifies how R will operate across all the folds.
```{r}

blr_wf <- workflow() %>%   ### initialize workflow
  add_model(blr_mdl) %>%
 # add_formula(species ~ sex + flipper_length_mm  )
   add_formula(species ~ flipper_length_mm + body_mass_g )
```

OK now let's apply the workflow to our folded training dataset, and see how it performs!

```{r}
blr_fit_folds <- blr_wf %>%
  fit_resamples(species_train_folds)

blr_fit_folds

### Average the predictive performance of the ten models:
collect_metrics(blr_fit_folds)
```


 2: 
Filter the penguins dataset to just include one species (most penguin species are not highly different in general size between males and females).  Do some exploratory plots to identify a few good variables that might help in this classification.  Do these variables make sense, why or why not?
Create two candidate model formulas using these predictor variables.  Analyze the filtered dataset and compare the performance of the two candidate models; select one model and explain your selection criteria (e.g., AIC/BIC, K-fold cross validation, AUC).
With this selected model, if you used cross-fold validation, retrain this model using the entire dataset.  Describe each of the variables and coefficients, including examples similar to those in the conceptual questions - e.g., for a given increase in variable X, how much more likely is the penguin to be sex Y.

